{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import future\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('intermediate_data/train_ft_processed.csv')\n",
    "test = pd.read_csv('intermediate_data/test_ft_processed.csv')\n",
    "y_train = pd.read_csv('intermediate_data/train_log1p.csv')\n",
    "y_train = y_train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[:100]\n",
    "y_train = y_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lasso__alpha': 0.008}\n",
      "0.153171283567\n"
     ]
    }
   ],
   "source": [
    "# param_grid = {'lasso__alpha':[0.0001, 0.001, 0.005, 0.01, 0.1, 1, 10]}\n",
    "param_grid = {'lasso__alpha':[0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009]}\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(random_state=228))\n",
    "gs = GridSearchCV(lasso, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "gs.fit(train, y_train)\n",
    "print gs.best_params_\n",
    "print np.sqrt(-gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernelridge__alpha': 0.05, 'kernelridge__coef0': 100000, 'kernelridge__kernel': 'polynomial', 'kernelridge__degree': 1}\n",
      "0.154524956261\n"
     ]
    }
   ],
   "source": [
    "# param_grid = [{'kernelridge__kernel':['linear'], \n",
    "#                'kernelridge__alpha':[0.0001, 0.001, 0.01, 0.1, 1, 10]}, \n",
    "#              {'kernelridge__kernel':['polynomial'],\n",
    "#               'kernelridge__degree': [1,2,3,4],\n",
    "#               'kernelridge__coef0': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "#               'kernelridge__alpha':[0.0001, 0.001, 0.005, 0.01, 0.1, 1, 10]},\n",
    "#              ]\n",
    "param_grid = [\n",
    "             {'kernelridge__kernel':['polynomial'],\n",
    "              'kernelridge__degree': [1,2],\n",
    "              'kernelridge__coef0': [500, 1000, 10000, 100000],\n",
    "              'kernelridge__alpha':[0.03, 0.05, 0.08]},\n",
    "             ]\n",
    "\n",
    "krr = make_pipeline(RobustScaler(), KernelRidge())\n",
    "gs = GridSearchCV(krr, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "gs.fit(train, y_train)\n",
    "print gs.best_params_\n",
    "print np.sqrt(-gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'auto', 'n_estimators': 500, 'max_depth': 10}\n",
      "0.175374760254\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'n_estimators':[500,1000,1500,2000],\n",
    "               'max_depth': [None,3,6,10],\n",
    "               'max_features': ['auto','sqrt']}\n",
    "             ]\n",
    "rf = RandomForestRegressor(n_jobs=-1, random_state=228)\n",
    "gs = GridSearchCV(rf, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "gs.fit(train, y_train)\n",
    "print gs.best_params_\n",
    "print np.sqrt(-gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 1, 'learning_rate': 0.1, 'n_estimators': 500, 'subsample': 0.8, 'reg_lambda': 0.01, 'max_depth': 3}\n",
      "0.161471961196\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'n_estimators':[500,1000,1500,2000],\n",
    "               'learning_rate':[0.1, 0.2, 0.3],\n",
    "               'max_depth':[3,6,10],\n",
    "               'subsample':[0.8, 1],\n",
    "               'colsample_bytree': [0.8, 1],\n",
    "               'reg_lambda':[0.01,0.1,1]}\n",
    "             ]\n",
    "xgb_model = xgb.XGBRegressor(n_jobs=-1, random_state=228)\n",
    "gs = GridSearchCV(xgb_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "gs.fit(train, y_train)\n",
    "print gs.best_params_\n",
    "print np.sqrt(-gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this approach, we add a meta-model on averaged base models and use the out-of-folds predictions of these base models to train our meta-model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import future\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('intermediate_data/train_ft_processed.csv')\n",
    "test = pd.read_csv('intermediate_data/test_ft_processed.csv')\n",
    "y_train = pd.read_csv('intermediate_data/train_log1p.csv')\n",
    "\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)\n",
    "y_train.reset_index(inplace=True)\n",
    "\n",
    "y_train = y_train['SalePrice']\n",
    "\n",
    "train = train.values.astype(np.float)\n",
    "test = test.values.astype(np.float)\n",
    "y_train = y_train.values.astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. As XGBoost does not work with mlxtend package, I have to write a stacking method myself\n",
    "### 2. XGBoost does not support clone method in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a stacking model with lasso, rf, xgb\n",
    "\n",
    "class StackingModels():\n",
    "    def __init__(self, n_folds=5):\n",
    "        self.lasso_folds = []\n",
    "        self.krr_folds = []\n",
    "        self.rf_folds = []\n",
    "        self.xgb_folds = []\n",
    "        self.meta_model = KernelRidge(alpha =0.01, kernel = 'linear')\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data and initiate new model on each fold, clone does not work on xgb\n",
    "    def fit(self, X, y):  \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        \n",
    "        lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.008,random_state=228))\n",
    "        krr = KernelRidge(alpha=0.05,kernel='polynomial',degree=1,coef0=100000)\n",
    "        rf = RandomForestRegressor(n_estimators=500,max_depth=10,max_features='auto',random_state=228)\n",
    "        # xgb_model = xgb.XGBRegressor(n_estimators=2000, random_state=228)\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], 4))\n",
    "        \n",
    "        for i in range(self.n_folds):\n",
    "            \n",
    "            lasso_ = clone(lasso)\n",
    "            krr_ = clone(krr)\n",
    "            rf_ = clone(rf)\n",
    "            xgb_ = xgb.XGBRegressor(colsample_bytree=1,learning_rate=0.1,n_estimators=500,\n",
    "                                    subsample=0.8,reg_lambda=0.01,max_depth=3,random_state=228)\n",
    "            \n",
    "            self.lasso_folds.append(lasso_)\n",
    "            self.krr_folds.append(krr_)\n",
    "            self.rf_folds.append(rf_)\n",
    "            self.xgb_folds.append(xgb_)\n",
    "            \n",
    "            holdout_ind = np.array(range(X.shape[0])[i::self.n_folds])\n",
    "            train_ind = np.array(list(set(range(X.shape[0]))-set(holdout_ind)))\n",
    "            \n",
    "            lasso_.fit(X[train_ind], y[train_ind])\n",
    "            krr_.fit(X[train_ind], y[train_ind])\n",
    "            rf_.fit(X[train_ind], y[train_ind])\n",
    "            xgb_.fit(X[train_ind], y[train_ind])\n",
    "            \n",
    "            y_pred = lasso_.predict(X[holdout_ind])\n",
    "            out_of_fold_predictions[holdout_ind, 0] = y_pred  \n",
    "            y_pred = krr_.predict(X[holdout_ind])\n",
    "            out_of_fold_predictions[holdout_ind, 1] = y_pred \n",
    "            y_pred = rf_.predict(X[holdout_ind])\n",
    "            out_of_fold_predictions[holdout_ind, 2] = y_pred          \n",
    "            y_pred = xgb_.predict(X[holdout_ind])\n",
    "            out_of_fold_predictions[holdout_ind, 3] = y_pred\n",
    "                \n",
    "        self.meta_model.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "\n",
    "        lasso_pred = np.column_stack([model.predict(X) for model in self.lasso_folds]).mean(axis=1)\n",
    "        krr_pred = np.column_stack([model.predict(X) for model in self.krr_folds]).mean(axis=1)\n",
    "        rf_pred = np.column_stack([model.predict(X) for model in self.rf_folds]).mean(axis=1)\n",
    "        xgb_pred = np.column_stack([model.predict(X) for model in self.xgb_folds]).mean(axis=1)\n",
    "        \n",
    "        meta_ft = np.column_stack((lasso_pred, krr_pred, rf_pred, xgb_pred))\n",
    "            \n",
    "        return self.meta_model.predict(meta_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_val_score does not work on self defined StackingModels, write a cross validation myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Models score: 0.1468 (0.0512)\n"
     ]
    }
   ],
   "source": [
    "# ##### for test\n",
    "train = train[:100]\n",
    "y_train = y_train[:100]\n",
    "\n",
    "n_folds=5\n",
    "rmse = []\n",
    "for train_index, test_index in KFold(n_folds, shuffle=True).split(train):\n",
    "    stack_ = StackingModels()\n",
    "    stack_.fit(train[train_index], y_train[train_index])\n",
    "    rmse.append(np.sqrt(np.mean((stack_.predict(train[test_index])-y_train[test_index])**2)))\n",
    "score = np.array(rmse)\n",
    "\n",
    "print(\"Stacking Models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import future\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('intermediate_data/train_ft_processed.csv')\n",
    "test = pd.read_csv('intermediate_data/test_ft_processed.csv')\n",
    "y_train = pd.read_csv('intermediate_data/train_log1p.csv')\n",
    "\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)\n",
    "y_train.reset_index(inplace=True)\n",
    "\n",
    "y_train = y_train['SalePrice']\n",
    "\n",
    "train = train.values.astype(np.float)\n",
    "test = test.values.astype(np.float)\n",
    "y_train = y_train.values.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackingModels()\n",
    "stack.fit(train, y_train)\n",
    "pred = stack.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1459\n",
      "Id           0\n",
      "SalePrice    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sample = pd.read_csv('raw_data/sample_submission.csv')\n",
    "sample.drop(columns=['SalePrice'], inplace=True)\n",
    "sub = pd.read_csv('raw_data/test.csv')\n",
    "sub = sub['Id'].values\n",
    "\n",
    "pred_inverse = np.expm1(pred)\n",
    "\n",
    "sub = sub.reshape(-1,1)\n",
    "pred_inverse = pred_inverse.reshape(-1,1)\n",
    "sub = np.concatenate((sub, pred_inverse), axis=1)\n",
    "sub = pd.DataFrame(sub, columns=['Id','SalePrice'])\n",
    "\n",
    "sub = sample.merge(sub, on=['Id'], how='left')\n",
    "\n",
    "sub.to_csv('outputs/20181029_skewFix_GridSearch_stack_4_krr.csv', index=False)\n",
    "print len(sub)\n",
    "print sub.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2",
   "language": "python",
   "name": "keraspython2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
